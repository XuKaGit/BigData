## 去重算法






### 1. MinHash

Hash method: hash就是将不同长度规则的文本转化成相同长度的字符串, 用这些相同长度的字符串来表示原文本. 通过比这些字符串的相似度来判断文本的重复性.

<p>

MinHash: 适用于大规模文本的hash去重算法. 这是一种将一个大的集合(比如一篇文档中的所有词组)压缩成一个短小的、固定长度的"签名"或"指纹的算法. 两个集合的 Jaccard 相似度(交集大小 / 并集大小)约等于它们各自 MinHash 签名的相似度.简单来说, 内容相似的文本, 其 MinHash 签名也会很相似. 这使得我们无需比较原文, 只需比较它们短小的签名即可.

步骤
- set_permutations 方法生成了 num_perm (例如 250) 个随机的哈希函数. 在 MinHash 的标准实现中, 每个哈希函数由一对随机数 (a, b) 定义,其形式为 h(x) = (a * x + b) % p.

- 创建"指纹": MinHash 算法会使用这 250 个独立的哈希函数, 对一篇文档中的所有 n-gram 特征进行哈希计算.

- 提取最小哈希值: 对于每一个哈希函数, 算法都会记录下它在该文档所有 n-gram 中计算出的最小哈希值.

- 形成签名: 将这 250 个哈希函数各自产生的最小哈希值组合在一起, 就形成了一个长度为 250 的向量. 这个向量就是这篇文档的 MinHash 签名或指纹.


### 2. LSH (Locality-Sensitive Hashing - 局部敏感哈希)

即使有了 MinHash, 在海量数据中逐一比较所有签名仍然非常耗时.

LSH 是一种高效的索引技术. 你可以把它想象成一个"智能分桶"系统, 它能将相似的 MinHash 签名(也就是相似的文本)大概率地放入同一个"桶"里.

当一个新文本到来时, 我们只需计算它的 MinHash 签名, 然后去 LSH 索引中查看它掉进了哪个桶, 再与桶里已有的少数几个签名进行比较即可, 极大地提高了查询效率