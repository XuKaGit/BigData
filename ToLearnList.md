- hdfs库
    `- client = KerberosClient(url)`
- Kerberos
    - krbcontext
    - KerberosClient

- PyHive
    - cursor
    - cursor: cur.fetchall()
- hiveserver2

`cur = connection(self.zkServers, "/hiveserver2", "serverUri", "hive", None, self.dbname)
`



- pyarrow








- 表的血缘追踪-- sparktool.py

- spark :  MapType(StringType(), StringType())



- datasketch



- ftlangdetect

- hive分区与并行度 : 写入表的时候





- hashmap = RDD5.saveAsMap()


